import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import pymysql
import json
import pytz
import warnings

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.filterwarnings('ignore')

# --- ì„¤ì • ---
# MySQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • (ë³¸ì¸ì˜ MySQL ì •ë³´ë¡œ ë³€ê²½í•˜ì„¸ìš”!)
MYSQL_HOST = "localhost"
MYSQL_USER = "root"
MYSQL_PASSWORD = "mysql@24!"
MYSQL_DB = "news_analysis_db"

# --- ë°ì´í„°ë² ì´ìŠ¤ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
@st.cache_resource
def get_mysql_connection():
    """MySQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì„¤ì •í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        conn = pymysql.connect(
            host=MYSQL_HOST,
            user=MYSQL_USER,
            password=MYSQL_PASSWORD,
            db=MYSQL_DB,
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        return conn
    except pymysql.Error as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
        return None

def fetch_analysis_dates(conn):
    """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ëª¨ë“  ê³ ìœ  ë¶„ì„ ë‚ ì§œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not conn:
        return []
    try:
        with conn.cursor() as cursor:
            # ì‹¤ì œ ê¸°ì‚¬ê°€ ì¡´ì¬í•˜ëŠ” ë‚ ì§œë§Œ ê³ ë ¤í•©ë‹ˆë‹¤.
            cursor.execute("SELECT DISTINCT DATE(analysis_date) AS analysis_date FROM news_articles ORDER BY analysis_date DESC;")
            results = cursor.fetchall()
            return [row['analysis_date'] for row in results]
    except pymysql.Error as e:
        st.error(f"ë¶„ì„ ë‚ ì§œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return []

def fetch_articles_and_topics_by_date_range(conn, start_date, end_date):
    """
    ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ ë‚´ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ì™€ í• ë‹¹ëœ í† í”½ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ê¸°ì‚¬ ë°ì´í„°ì™€ í† í”½ ê²°ê³¼ ë° í† í”½ ì •ë³´ê°€ ì¡°ì¸ëœ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not conn:
        return pd.DataFrame()
    try:
        with conn.cursor() as cursor:
            sql = """
            SELECT
                DATE(na.analysis_date) AS analysis_day,
                na.title,
                na.link,
                na.description,
                na.pub_date,
                tr.topic_id,
                tr.probability,
                ti.topic_name,
                ti.representation
            FROM
                news_articles na
            JOIN
                topic_results tr ON na.id = tr.article_id
            LEFT JOIN
                topic_info ti ON tr.topic_id = ti.topic_id AND DATE(ti.analysis_date) = DATE(na.analysis_date)
            WHERE
                DATE(na.analysis_date) BETWEEN %s AND %s
            ORDER BY
                na.analysis_date DESC, tr.probability DESC;
            """
            cursor.execute(sql, (start_date, end_date))
            data = cursor.fetchall()
            df = pd.DataFrame(data)

            # representation ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë‹¤ì‹œ ë³€í™˜
            if 'representation' in df.columns:
                df['representation'] = df['representation'].apply(lambda x: json.loads(x) if x else [])

            return df
    except pymysql.Error as e:
        st.error(f"ê¸°ê°„ë³„ ê¸°ì‚¬ ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# --- Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ í•¨ìˆ˜ ---

def display_topic_analysis_results(df, selected_date_for_display):
    """ì„ íƒëœ ë‚ ì§œì˜ í† í”½ ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤ (ë§‰ëŒ€ ê·¸ë˜í”„, í‚¤ì›Œë“œ, ê¸°ì‚¬ ëª©ë¡)."""
    
    if df.empty:
        st.warning(f"ì„ íƒëœ ë‚ ì§œ ({selected_date_for_display.strftime('%Y-%m-%d')})ì— ëŒ€í•œ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë…¸ì´ì¦ˆ í† í”½(-1) í•„í„°ë§
    df_filtered = df[df['topic_id'] != -1].copy()
    
    if df_filtered.empty:
        st.info("ë…¸ì´ì¦ˆ í† í”½ì„ ì œì™¸í•œ ìœ íš¨í•œ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í† í”½ë³„ ê¸°ì‚¬ ìˆ˜ ì§‘ê³„ ë° í† í”½ ì •ë³´ ë³‘í•©
    topic_counts_for_day = df_filtered.groupby('topic_name').size().reset_index(name='count')
    # Merge with topic info to get representation. Ensure unique representation per topic_name.
    # We need to get topic_id and representation for the selected date from the original single_day_df_filtered.
    topic_info_for_day = df_filtered[['topic_id', 'topic_name', 'representation']].drop_duplicates(subset=['topic_id', 'topic_name'])
    topic_info_for_day = topic_info_for_day[topic_info_for_day['topic_id'] != -1] # Exclude noise topic

    topic_overview_df = pd.merge(topic_counts_for_day, topic_info_for_day, on='topic_name', how='left')
    topic_overview_df = topic_overview_df.rename(columns={'count': 'topic_count'})
    topic_overview_df = topic_overview_df.sort_values(by='topic_count', ascending=False)

    # --- ìƒìœ„ 10ê°œ í† í”½ë§Œ ì„ íƒ ---
    top_10_topics_df = topic_overview_df.head(10)


    col1, col2 = st.columns([0.7, 0.3])

    with col1:
        # ìƒìœ„ 10ê°œ í† í”½ìœ¼ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        fig = px.bar(
            top_10_topics_df,
            x='topic_name',
            y='topic_count',
            title='ìƒìœ„ 10ê°œ í† í”½ë³„ ê¸°ì‚¬ ìˆ˜', # ì œëª© ë³€ê²½
            labels={'topic_name': 'í† í”½', 'topic_count': 'ê¸°ì‚¬ ìˆ˜'},
            hover_data={'representation': True},
            color_discrete_sequence=px.colors.qualitative.Pastel
        )
        fig.update_layout(xaxis={'categoryorder':'total descending'}, showlegend=False)
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.markdown("### ì£¼ìš” í† í”½ ì •ë³´")
        # ìƒìœ„ 5ê°œ í† í”½ ì •ë³´ í‘œì‹œ (ê¸°ì¡´ê³¼ ë™ì¼)
        for index, row in topic_overview_df.head(5).iterrows():
            st.markdown(f"**í† í”½ {row['topic_id']}**: {row['topic_name']}")
            st.markdown(f"**ê¸°ì‚¬ ìˆ˜**: {row['topic_count']}")
            st.markdown(f"**í•µì‹¬ í‚¤ì›Œë“œ**: {', '.join(row['representation'])}")
            st.markdown("---")

    st.subheader("ğŸ“° í† í”½ë³„ ê¸°ì‚¬ ëª©ë¡")

    # í† í”½ ì„ íƒ ë°•ìŠ¤ëŠ” ì—¬ì „íˆ ëª¨ë“  í† í”½ì„ í¬í•¨í•©ë‹ˆë‹¤. (íŠ¹ì • í† í”½ì˜ ê¸°ì‚¬ ëª©ë¡ í™•ì¸ ëª©ì )
    selected_topic_name_for_articles = st.selectbox(
        "ìì„¸íˆ ë³¼ í† í”½ ì„ íƒ",
        options=['ì „ì²´ ê¸°ì‚¬'] + topic_overview_df['topic_name'].tolist(),
        key=f"articles_select_{selected_date_for_display.strftime('%Y%m%d')}"
    )

    display_articles_df = df_filtered.copy()
    if selected_topic_name_for_articles != 'ì „ì²´ ê¸°ì‚¬':
        display_articles_df = display_articles_df[display_articles_df['topic_name'] == selected_topic_name_for_articles]
    
    display_articles_df['pub_date_dt'] = pd.to_datetime(display_articles_df['pub_date'])
    display_articles_df = display_articles_df.sort_values(by=['probability', 'pub_date_dt'], ascending=[False, False])

    if not display_articles_df.empty:
        for index, row in display_articles_df.iterrows():
            with st.expander(f"**[{row['title']}]** (í† í”½: {row['topic_name']}, í™•ë¥ : {row['probability']:.2f}) - {pd.to_datetime(row['pub_date']).strftime('%Y-%m-%d %H:%M:%S')}"):
                st.markdown(f"**ì›ë³¸ ë§í¬**: [{row['link']}]({row['link']})")
                st.markdown(f"**ê¸°ì‚¬ ìš”ì•½**: {row['description']}")
            st.markdown("---")
    else:
        st.info("ì„ íƒëœ í† í”½ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")


def page_todays_topics(conn):
    """ì˜¤ëŠ˜ì˜ í† í”½ì„ ë³´ì—¬ì£¼ëŠ” í˜ì´ì§€."""
    st.header("âœ¨ ì˜¤ëŠ˜ì˜ í† í”½")
    st.markdown("ê°€ì¥ ìµœê·¼ ë¶„ì„ëœ ë‚ ì§œì˜ ì£¼ìš” ë‰´ìŠ¤ í† í”½ì„ í™•ì¸í•˜ì„¸ìš”.")

    analysis_dates = fetch_analysis_dates(conn)
    if not analysis_dates:
        st.warning("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶„ì„ëœ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    most_recent_date = analysis_dates[0] # ê°€ì¥ ìµœì‹  ë‚ ì§œ
    st.info(f"ë¶„ì„ ë‚ ì§œ: **{most_recent_date.strftime('%Yë…„ %mì›” %dì¼')}**")

    recent_day_df = fetch_articles_and_topics_by_date_range(conn, most_recent_date, most_recent_date)
    display_topic_analysis_results(recent_day_df, most_recent_date)


def page_topic_trend_over_time(conn):
    """ê¸°ê°„ë³„ í† í”½ íŠ¸ë Œë“œë¥¼ ë³´ì—¬ì£¼ëŠ” í˜ì´ì§€."""
    st.header("ğŸ“ˆ ê¸°ê°„ë³„ í† í”½ íŠ¸ë Œë“œ ë¶„ì„")
    st.markdown("ì„ íƒí•œ ê¸°ê°„ ë™ì•ˆ ë‰´ìŠ¤ í† í”½ì˜ ë³€í™”ë¥¼ ê·¸ë˜í”„ë¡œ í™•ì¸í•˜ì„¸ìš”.")

    analysis_dates = fetch_analysis_dates(conn)
    if not analysis_dates:
        st.warning("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶„ì„ëœ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    min_date_available = min(analysis_dates)
    max_date_available = max(analysis_dates)

    col_start, col_end = st.columns(2)
    with col_start:
        start_date = st.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            value=max_date_available - timedelta(days=6), # ê¸°ë³¸ê°’: ìµœê·¼ 7ì¼
            min_value=min_date_available,
            max_value=max_date_available
        )
    with col_end:
        end_date = st.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            value=max_date_available,
            min_value=min_date_available,
            max_value=max_date_available
        )

    if start_date > end_date:
        st.error("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ë¹ ë¥´ê±°ë‚˜ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.")
        return

    st.info(f"ë¶„ì„ ê¸°ê°„: **{start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}**")
    
    trend_df = fetch_articles_and_topics_by_date_range(conn, start_date, end_date)

    if trend_df.empty:
        st.warning("ì„ íƒëœ ê¸°ê°„ì— ëŒ€í•œ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ë…¸ì´ì¦ˆ í† í”½(-1) í•„í„°ë§
    trend_df_filtered = trend_df[trend_df['topic_id'] != -1].copy()

    if not trend_df_filtered.empty:
        # ë‚ ì§œë³„, í† í”½ë³„ ê¸°ì‚¬ ìˆ˜ ì§‘ê³„
        topic_daily_counts = trend_df_filtered.groupby(['analysis_day', 'topic_name']).size().reset_index(name='article_count')
        
        # ê¸°ê°„ ë‚´ ì „ì²´ ê¸°ì‚¬ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ 10ê°œ í† í”½ ì„ ì •
        top_topics_in_period = topic_daily_counts.groupby('topic_name')['article_count'].sum().nlargest(10).index.tolist()
        
        # ìƒìœ„ í† í”½ë§Œ í•„í„°ë§
        topic_daily_counts_top = topic_daily_counts[topic_daily_counts['topic_name'].isin(top_topics_in_period)]

        if not topic_daily_counts_top.empty:
            fig_trend = px.line(
                topic_daily_counts_top,
                x='analysis_day',
                y='article_count',
                color='topic_name',
                title='ê¸°ê°„ë³„ ì£¼ìš” í† í”½ ê¸°ì‚¬ ìˆ˜ ì¶”ì´ (ìƒìœ„ 10ê°œ í† í”½)', # ì œëª© ìœ ì§€ (ì´ë¯¸ ìƒìœ„ 10ê°œë§Œ í•„í„°ë§)
                labels={'analysis_day': 'ë‚ ì§œ', 'article_count': 'ê¸°ì‚¬ ìˆ˜', 'topic_name': 'í† í”½ ì´ë¦„'},
                hover_data={'topic_name': True, 'article_count': True}
            )
            fig_trend.update_layout(hovermode="x unified")
            st.plotly_chart(fig_trend, use_container_width=True)
        else:
            st.info("ì„ íƒëœ ê¸°ê°„ ë‚´ì—ì„œ ìœ íš¨í•œ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ì„ íƒëœ ê¸°ê°„ì— ë…¸ì´ì¦ˆ í† í”½ì„ ì œì™¸í•œ ìœ íš¨í•œ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")


def page_past_topics_from_db(conn):
    """DBì— ì €ì¥ëœ ê³¼ê±° í† í”½ì„ ë³´ì—¬ì£¼ëŠ” í˜ì´ì§€."""
    st.header("ğŸ—“ï¸ ê³¼ê±° í† í”½ ë³´ê¸°")
    st.markdown("ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ íŠ¹ì • ë‚ ì§œì˜ í† í”½ ë¶„ì„ ê²°ê³¼ë¥¼ ì¡°íšŒí•˜ì„¸ìš”.")

    analysis_dates = fetch_analysis_dates(conn)
    if not analysis_dates:
        st.warning("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶„ì„ëœ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    selected_past_date = st.selectbox(
        "ê³¼ê±° ë¶„ì„ ë‚ ì§œ ì„ íƒ",
        options=analysis_dates,
        index=0, # ê¸°ë³¸ê°’ìœ¼ë¡œ ê°€ì¥ ìµœê·¼ ë‚ ì§œ
        format_func=lambda x: x.strftime('%Yë…„ %mì›” %dì¼')
    )
    st.info(f"ì„ íƒëœ ê³¼ê±° ë¶„ì„ ë‚ ì§œ: **{selected_past_date.strftime('%Yë…„ %mì›” %dì¼')}**")

    past_day_df = fetch_articles_and_topics_by_date_range(conn, selected_past_date, selected_past_date)
    display_topic_analysis_results(past_day_df, selected_past_date)


# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ---
if __name__ == "__main__":
    st.set_page_config(layout="wide", page_title="ë‰´ìŠ¤ í† í”½ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")

    st.sidebar.title("ë©”ë‰´")
    
    # ì‚¬ì´ë“œë°”ì—ì„œ ê¸°ëŠ¥ ì„ íƒ
    page_selection = st.sidebar.radio(
        "ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:",
        ("ì˜¤ëŠ˜ì˜ í† í”½", "ê¸°ê°„ë³„ í† í”½ íŠ¸ë Œë“œ", "ê³¼ê±° í† í”½ ë³´ê¸°")
    )

    conn = get_mysql_connection()
    if not conn:
        st.stop() # DB ì—°ê²° ì‹¤íŒ¨ ì‹œ ì•± ì¤‘ë‹¨

    if page_selection == "ì˜¤ëŠ˜ì˜ í† í”½":
        page_todays_topics(conn)
    elif page_selection == "ê¸°ê°„ë³„ í† í”½ íŠ¸ë Œë“œ":
        page_topic_trend_over_time(conn)
    elif page_selection == "ê³¼ê±° í† í”½ ë³´ê¸°":
        page_past_topics_from_db(conn)

    st.markdown("---")
    st.markdown("ì•±ì— ëŒ€í•œ í”¼ë“œë°±ì´ë‚˜ ê°œì„  ì‚¬í•­ì´ ìˆìœ¼ì‹œë©´ ì•Œë ¤ì£¼ì„¸ìš”!")