import streamlit as st
import pandas as pd
import os
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import plotly.express as px
import pymysql # MySQL ì—°ë™
import json # JSON ë¬¸ìì—´ íŒŒì‹±ì„ ìœ„í•´
from datetime import datetime, timedelta

# í°íŠ¸ ì„¤ì • (ì‚¬ìš©ì OSì— ë”°ë¼ ë³€ê²½ í•„ìš”)
try:
    plt.rcParams['font.family'] = 'AppleGothic'
except:
    try:
        plt.rcParams['font.family'] = 'Malgun Gothic'
    except:
        st.warning("ì‹œìŠ¤í…œ í°íŠ¸ ì„¤ì •ì— ë¬¸ì œê°€ ìˆì–´ í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'AppleGothic' ë˜ëŠ” 'Malgun Gothic' í°íŠ¸ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
plt.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# MySQL ì„¤ì • (daily_news_analyzer.pyì™€ ë™ì¼í•´ì•¼ í•¨)
MYSQL_HOST = "localhost"
MYSQL_USER = "root"
MYSQL_PASSWORD = "mysql@24!"
MYSQL_DB = "news_analysis_db" # ìƒì„±í•œ ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸

# --- MySQLì—ì„œ ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
@st.cache_data(ttl=300) # 5ë¶„ë§ˆë‹¤ ìºì‹œ ê°±ì‹  (ìƒˆë¡œìš´ ë¶„ì„ ê²°ê³¼ ë°˜ì˜)
def load_analysis_results_from_mysql(analysis_date_str):
    conn = None
    try:
        conn = pymysql.connect(
            host=MYSQL_HOST,
            user=MYSQL_USER,
            password=MYSQL_PASSWORD,
            db=MYSQL_DB,
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        
        analysis_date = datetime.strptime(analysis_date_str, '%Y-%m-%d')
        
        # news_articles ë° topic_results ì¡°ì¸í•˜ì—¬ ê°€ì ¸ì˜¤ê¸°
        # analysis_dateë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
        select_articles_sql = """
        SELECT
            na.title,
            na.link,
            na.original_text,
            tr.topic_id AS topic,
            tr.probability,
            na.pub_date,
            na.analysis_date
        FROM news_articles na
        JOIN topic_results tr ON na.id = tr.article_id
        WHERE DATE(na.analysis_date) = %s;
        """
        # read_sqlì˜ paramsëŠ” íŠœí”Œ í˜•íƒœë¡œ ì „ë‹¬í•´ì•¼ í•¨
        doc_topic_df = pd.read_sql(select_articles_sql, conn, params=(analysis_date.strftime('%Y-%m-%d'),))
        
        # topic_info í…Œì´ë¸”ì—ì„œ í† í”½ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        select_topic_info_sql = """
        SELECT
            topic_id AS Topic,
            topic_count AS `Count`,
            topic_name AS Name,
            representation AS Representation
        FROM topic_info
        WHERE DATE(analysis_date) = %s;
        """
        freq_df = pd.read_sql(select_topic_info_sql, conn, params=(analysis_date.strftime('%Y-%m-%d'),))
        
        # Representation ì»¬ëŸ¼ì€ JSON ë¬¸ìì—´ë¡œ ì €ì¥ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        if 'Representation' in freq_df.columns:
            # === ì´ ë¶€ë¶„ì„ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •í•©ë‹ˆë‹¤. ===
            freq_df['Representation'] = freq_df['Representation'].apply(
                lambda x: json.loads(x) if isinstance(x, str) and x.strip() else []
            )
            # ======================================

        return doc_topic_df, freq_df, analysis_date

    except pymysql.Error as e:
        st.error(f"MySQL ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. MySQL ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, ì¸ì¦ ì •ë³´ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None
    except json.JSONDecodeError as e: # JSON íŒŒì‹± ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€
        # ì´ ë©”ì‹œì§€ê°€ ëœ¨ë©´ DBì— ìœ íš¨í•˜ì§€ ì•Šì€ JSONì´ ìˆë‹¤ëŠ” ëœ»ì´ë¯€ë¡œ, DBë¥¼ í™•ì¸í•´ì•¼ í•¨
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: Representation ì»¬ëŸ¼ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. DBì˜ í•´ë‹¹ ë°ì´í„°ê°€ ìœ íš¨í•œ JSON í˜•ì‹ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None, None, None
    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None
    finally:
        if conn:
            conn.close()

# --- MySQLì—ì„œ ë¶„ì„ì´ ìˆ˜í–‰ëœ ë‚ ì§œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ---
@st.cache_data(ttl=3600) # 1ì‹œê°„ë§ˆë‹¤ ê°±ì‹  (ìƒˆë¡œìš´ ë¶„ì„ ë‚ ì§œê°€ ì¶”ê°€ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
def get_available_analysis_dates():
    conn = None
    try:
        conn = pymysql.connect(
            host=MYSQL_HOST,
            user=MYSQL_USER,
            password=MYSQL_PASSWORD,
            db=MYSQL_DB,
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        cursor = conn.cursor()
        # analysis_dateê°€ ìˆëŠ” ëª¨ë“  ê³ ìœ í•œ ë‚ ì§œë¥¼ ìµœì‹ ìˆœìœ¼ë¡œ ê°€ì ¸ì˜´
        cursor.execute("SELECT DISTINCT DATE(analysis_date) AS distinct_date FROM news_articles ORDER BY distinct_date DESC;")
        dates = [row['distinct_date'].strftime('%Y-%m-%d') for row in cursor.fetchall()]
        return dates
    except pymysql.Error as e:
        st.error(f"MySQLì—ì„œ ë¶„ì„ ë‚ ì§œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    finally:
        if conn:
            conn.close()

# --- ì´ìŠˆ ìˆœìœ„í™” í•¨ìˆ˜ ---
def rank_issues(topic_freq_df):
    ranked_df = topic_freq_df[topic_freq_df.Topic != -1].copy() # ë…¸ì´ì¦ˆ í† í”½(-1) ì œì™¸
    ranked_df = ranked_df.sort_values(by='Count', ascending=False) # ë¬¸ì„œ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    ranked_df = ranked_df[['Topic', 'Count', 'Name', 'Representation']]
    ranked_df.rename(columns={'Name': 'ëŒ€í‘œ í‚¤ì›Œë“œ ê·¸ë£¹', 'Representation': 'í•µì‹¬ í‚¤ì›Œë“œ'}, inplace=True)
    return ranked_df

# --- ì‹œê°í™” í•¨ìˆ˜ ---
def plot_wordcloud(topic_id, words_scores):
    if topic_id == -1:
        st.warning("ì„ íƒëœ í† í”½ì€ ë…¸ì´ì¦ˆ í† í”½(-1)ì…ë‹ˆë‹¤. ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if not words_scores:
        st.warning(f"í† í”½ {topic_id}ì— ëŒ€í•œ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    word_freq = {word: score for word, score in words_scores}
    
    font_path = None
    # macOS í°íŠ¸ ê²½ë¡œ (ì˜ˆì‹œ)
    if 'AppleGothic' in plt.rcParams['font.family'] and os.path.exists('/System/Library/Fonts/AppleSDGothicNeo.ttc'):
        font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'
    # Windows í°íŠ¸ ê²½ë¡œ (ì˜ˆì‹œ)
    elif 'Malgun Gothic' in plt.rcParams['font.family'] and os.path.exists('C:/Windows/Fonts/malgun.ttf'):
        font_path = 'C:/Windows/Fonts/malgun.ttf'
    
    if font_path and os.path.exists(font_path):
        wc = WordCloud(font_path=font_path,
                       width=800, height=400, background_color='white',
                       max_words=50, collocations=False).generate_from_frequencies(word_freq)
    else:
        st.warning(f"ì›Œë“œí´ë¼ìš°ë“œ í°íŠ¸ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²½ë¡œ: {font_path}) ê¸°ë³¸ í°íŠ¸ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        wc = WordCloud(width=800, height=400, background_color='white',
                       max_words=50, collocations=False).generate_from_frequencies(word_freq)
    
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

def plot_topic_distribution(freq_df):
    # ë…¸ì´ì¦ˆ í† í”½(-1)ì„ ì œì™¸í•˜ê³  ìƒìœ„ 10ê°œ í† í”½ë§Œ ì‹œê°í™”
    filtered_freq_df = freq_df[freq_df.Topic != -1].head(10)
    if filtered_freq_df.empty:
        st.info("í‘œì‹œí•  í† í”½ ë¶„í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    fig = px.bar(filtered_freq_df, x='Topic', y='Count', 
                 title='ìƒìœ„ 10ê°œ í† í”½ ë¬¸ì„œ ìˆ˜ ë¶„í¬', 
                 hover_data=['Representation'], # ë§ˆìš°ìŠ¤ ì˜¤ë²„ ì‹œ í•µì‹¬ í‚¤ì›Œë“œ í‘œì‹œ
                 labels={'Topic': 'í† í”½ ID', 'Count': 'ë¬¸ì„œ ìˆ˜'},
                 color_discrete_sequence=px.colors.qualitative.Pastel) # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
    fig.update_xaxes(type='category') # Xì¶•ì„ ì¹´í…Œê³ ë¦¬í˜•ìœ¼ë¡œ ì„¤ì •
    st.plotly_chart(fig, use_container_width=True) # ì»¨í…Œì´ë„ˆ ë„ˆë¹„ì— ë§ì¶¤

# --- Streamlit ì•± ë©”ì¸ ë¡œì§ ---
def main():
    st.set_page_config(layout="wide") # ë„“ì€ ë ˆì´ì•„ì›ƒ ì‚¬ìš©
    st.title("â˜€ï¸ êµ¿ëª¨ë‹, ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ ì´ìŠˆ ëŒ€ì‹œë³´ë“œ")
    st.write("ë§¤ì¼ ì•„ì¹¨ ìë™ìœ¼ë¡œ ë¶„ì„ëœ ìµœì‹  ë‰´ìŠ¤ ì´ìŠˆì™€ ê³¼ê±° ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    st.sidebar.header("ë¶„ì„ ë‚ ì§œ ì„ íƒ")
    available_dates = get_available_analysis_dates() # MySQLì—ì„œ ë¶„ì„ ë‚ ì§œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    
    if not available_dates:
        st.error("MySQL ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¶„ì„ëœ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'daily_news_analyzer.py' ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€, ê·¸ë¦¬ê³  MySQL ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop() # ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•Šê³  ì•± ì¢…ë£Œ

    # ê°€ì¥ ìµœì‹  ë‚ ì§œë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„ íƒ
    selected_date_str = st.sidebar.selectbox("ë¶„ì„ ë‚ ì§œ ì„ íƒ:", available_dates)

    doc_topic_df, freq_df, analysis_time = load_analysis_results_from_mysql(selected_date_str)

    # analysis_timeì´ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì²´í¬
    if doc_topic_df is None or freq_df is None or analysis_time is None: 
        st.info("ì„ íƒëœ ë‚ ì§œì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ê°€ MySQLì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    st.sidebar.info(f"ì„ íƒëœ ë¶„ì„ ì‹œê°: **{analysis_time.strftime('%Yë…„ %mì›” %dì¼')}**")
    st.sidebar.info(f"ì´ ë¶„ì„ ê¸°ì‚¬ ìˆ˜: **{len(doc_topic_df)}ê°œ**")
    st.sidebar.info(f"ì´ ë°œê²¬ í† í”½ ìˆ˜: **{len(freq_df[freq_df.Topic != -1])}ê°œ**")

    st.markdown("---")
    st.header(f"ğŸ“Š {analysis_time.strftime('%Yë…„ %mì›” %dì¼')} ì£¼ìš” ì´ìŠˆ ë¶„ì„ ê²°ê³¼")

    # íƒ­ êµ¬ì„±
    tab1, tab2 = st.tabs(["ì£¼ìš” ì´ìŠˆ ìš”ì•½", "í† í”½ ìƒì„¸ ë¶„ì„"])

    with tab1:
        st.subheader("ğŸ’¡ í•µì‹¬ ë‰´ìŠ¤ ì´ìŠˆ (TOP 5)")
        ranked_issues_df = rank_issues(freq_df)
        if not ranked_issues_df.empty:
            st.dataframe(ranked_issues_df.head(5).style.set_properties(**{'font-size': '16px'}), use_container_width=True, hide_index=True)
        else:
            st.info("ë¶„ì„ëœ ì£¼ìš” ì´ìŠˆê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("ğŸ“ˆ í† í”½ ë¬¸ì„œ ìˆ˜ ë¶„í¬ (ìƒìœ„ 10ê°œ)")
        plot_topic_distribution(freq_df)

    with tab2:
        st.subheader("ğŸ” íŠ¹ì • í† í”½ ìƒì„¸ ë¶„ì„")
        
        available_topics = sorted(freq_df[freq_df.Topic != -1]['Topic'].tolist())
        if not available_topics:
            st.info("ë¶„ì„ëœ í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        # í† í”½ ID ì„ íƒ ë“œë¡­ë‹¤ìš´ (í† í”½ IDì™€ í•µì‹¬ í‚¤ì›Œë“œë¥¼ í•¨ê»˜ í‘œì‹œ)
        selected_topic = st.selectbox(
            "ë¶„ì„í•  í† í”½ IDë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
            options=available_topics,
            # freq.Topic ì´ ì•„ë‹ˆë¼ freq_df.Topic ì…ë‹ˆë‹¤.
            format_func=lambda x: f"í† í”½ {x} ({', '.join(freq_df[freq_df.Topic == x]['Representation'].iloc[0])})" 
        )

        if selected_topic is not None:
            st.write(f"#### ì„ íƒëœ í† í”½: **{selected_topic}**")
            topic_info = freq_df[freq_df.Topic == selected_topic]
            if not topic_info.empty:
                st.write(f"- **ë¬¸ì„œ ìˆ˜:** {topic_info['Count'].iloc[0]}ê°œ")
                st.write(f"- **ëŒ€í‘œ í‚¤ì›Œë“œ ê·¸ë£¹:** {topic_info['Name'].iloc[0]}")
                st.write(f"- **í•µì‹¬ í‚¤ì›Œë“œ:** {', '.join(topic_info['Representation'].iloc[0])}")
                
            st.markdown("---")
            st.subheader(f"ì›Œë“œí´ë¼ìš°ë“œ (í† í”½ {selected_topic})")
            # BERTopicì˜ get_topic()ì²˜ëŸ¼ í† í”½ í‚¤ì›Œë“œì™€ ì ìˆ˜ë¥¼ í•¨ê»˜ ì œê³µí•˜ê¸° ì–´ë µê¸° ë•Œë¬¸ì—
            # Representationì˜ ê° í‚¤ì›Œë“œì— ì„ì‹œë¡œ 1.0 ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì—¬ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            # Representationì´ ë¹„ì–´ìˆì„ ê²½ìš°ì— ëŒ€í•œ ì²˜ë¦¬ ì¶”ê°€
            if not topic_info.empty and topic_info['Representation'].iloc[0]: # ë¹„ì–´ìˆëŠ” ë¦¬ìŠ¤íŠ¸ ì—¬ë¶€ í™•ì¸ ì¶”ê°€
                plot_wordcloud(selected_topic, [(word, 1.0) for word in topic_info['Representation'].iloc[0]])
            else:
                st.warning("ì´ í† í”½ì— ëŒ€í•œ ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")


            st.markdown("---")
            st.subheader(f"í† í”½ {selected_topic} ê´€ë ¨ ë‰´ìŠ¤ ê¸°ì‚¬ ì˜ˆì‹œ")
            # í•´ë‹¹ í† í”½ì— ì†í•˜ëŠ” ê¸°ì‚¬ë“¤ì„ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
            topic_articles_df = doc_topic_df[doc_topic_df.topic == selected_topic].sort_values(by='probability', ascending=False)
            
            if not topic_articles_df.empty:
                num_display_articles = st.slider("í‘œì‹œí•  ê¸°ì‚¬ ìˆ˜", 1, min(10, len(topic_articles_df)), 3)
                for i, row in topic_articles_df.head(num_display_articles).iterrows():
                    # st.expanderë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì‚¬ ë‚´ìš©ì„ ìˆ¨ê¸°ê³  í¼ì¹  ìˆ˜ ìˆê²Œ í•¨
                    st.expander(f"**{row['title']}** (í™•ë¥ : {row['probability']:.2f})").markdown(f"*{row['link']}*\n\n{row['original_text']}")
            else:
                st.info(f"í† í”½ {selected_topic}ì— í•´ë‹¹í•˜ëŠ” ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()